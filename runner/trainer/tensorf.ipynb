{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/project/jacobcha/nk643/TensoRFReproduce')\n",
    "# sys.path.append('/project/jacobcha/nk643/TensoRFReproduce/runner/trainer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-02 10:15:07.237038: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-02 10:15:07.265616: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-02 10:15:07.265644: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-02 10:15:07.266581: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-02 10:15:07.272644: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-02 10:15:08.878132: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import DictConfig, OmegaConf\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import json, random\n",
    "from data.blender import BlenderDataset\n",
    "from model.extractor.tensorf import TensorVM\n",
    "from model.renderer.tensorf import TensoRFRenderer\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import datetime\n",
    "import sys\n",
    "import imageio\n",
    "import torch\n",
    "#from .tensorf_utils import *\n",
    "from runner.trainer.tensorf_utils import *\n",
    "\n",
    "class SimpleSampler:\n",
    "    def __init__(self, total, batch):\n",
    "        self.total = total\n",
    "        self.batch = batch\n",
    "        self.curr = total\n",
    "        self.ids = None\n",
    "\n",
    "    def nextids(self):\n",
    "        self.curr+=self.batch\n",
    "        if self.curr + self.batch > self.total:\n",
    "            self.ids = torch.LongTensor(np.random.permutation(self.total))\n",
    "            self.curr = 0\n",
    "        return self.ids[self.curr:self.curr+self.batch]\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluation(test_dataset,tensorf, args, renderer, savePath=None, N_vis=5, prtx='', N_samples=-1,\n",
    "               white_bg=False, ndc_ray=False, compute_extra_metrics=True, device='cuda'):\n",
    "    PSNRs, rgb_maps, depth_maps = [], [], []\n",
    "    ssims,l_alex,l_vgg=[],[],[]\n",
    "    os.makedirs(savePath, exist_ok=True)\n",
    "    os.makedirs(savePath+\"/rgbd\", exist_ok=True)\n",
    "\n",
    "    try:\n",
    "        tqdm._instances.clear()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    near_far = test_dataset.near_far\n",
    "    img_eval_interval = 1 if N_vis < 0 else max(test_dataset.all_rays.shape[0] // N_vis,1)\n",
    "    idxs = list(range(0, test_dataset.all_rays.shape[0], img_eval_interval))\n",
    "    for idx, samples in tqdm(enumerate(test_dataset.all_rays[0::img_eval_interval]), file=sys.stdout):\n",
    "\n",
    "        W, H = test_dataset.img_wh\n",
    "        rays = samples.view(-1,samples.shape[-1])\n",
    "\n",
    "        rgb_map, _, depth_map, _, _ = renderer(rays, tensorf, chunk=4096, N_samples=N_samples,\n",
    "                                        ndc_ray=ndc_ray, white_bg = white_bg, device=device)\n",
    "        rgb_map = rgb_map.clamp(0.0, 1.0)\n",
    "\n",
    "        rgb_map, depth_map = rgb_map.reshape(H, W, 3).cpu(), depth_map.reshape(H, W).cpu()\n",
    "\n",
    "        depth_map, _ = visualize_depth_numpy(depth_map.numpy(),near_far)\n",
    "        if len(test_dataset.all_rgbs):\n",
    "            gt_rgb = test_dataset.all_rgbs[idxs[idx]].view(H, W, 3)\n",
    "            loss = torch.mean((rgb_map - gt_rgb) ** 2)\n",
    "            PSNRs.append(-10.0 * np.log(loss.item()) / np.log(10.0))\n",
    "\n",
    "            if compute_extra_metrics:\n",
    "                ssim = rgb_ssim(rgb_map, gt_rgb, 1)\n",
    "                l_a = rgb_lpips(gt_rgb.numpy(), rgb_map.numpy(), 'alex', tensorf.device)\n",
    "                l_v = rgb_lpips(gt_rgb.numpy(), rgb_map.numpy(), 'vgg', tensorf.device)\n",
    "                ssims.append(ssim)\n",
    "                l_alex.append(l_a)\n",
    "                l_vgg.append(l_v)\n",
    "\n",
    "        rgb_map = (rgb_map.numpy() * 255).astype('uint8')\n",
    "        # rgb_map = np.concatenate((rgb_map, depth_map), axis=1)\n",
    "        rgb_maps.append(rgb_map)\n",
    "        depth_maps.append(depth_map)\n",
    "        if savePath is not None:\n",
    "            imageio.imwrite(f'{savePath}/{prtx}{idx:03d}.png', rgb_map)\n",
    "            rgb_map = np.concatenate((rgb_map, depth_map), axis=1)\n",
    "            imageio.imwrite(f'{savePath}/rgbd/{prtx}{idx:03d}.png', rgb_map)\n",
    "\n",
    "    imageio.mimwrite(f'{savePath}/{prtx}video.mp4', np.stack(rgb_maps), fps=30, quality=10)\n",
    "    imageio.mimwrite(f'{savePath}/{prtx}depthvideo.mp4', np.stack(depth_maps), fps=30, quality=10)\n",
    "\n",
    "    if PSNRs:\n",
    "        psnr = np.mean(np.asarray(PSNRs))\n",
    "        if compute_extra_metrics:\n",
    "            ssim = np.mean(np.asarray(ssims))\n",
    "            l_a = np.mean(np.asarray(l_alex))\n",
    "            l_v = np.mean(np.asarray(l_vgg))\n",
    "            np.savetxt(f'{savePath}/{prtx}mean.txt', np.asarray([psnr, ssim, l_a, l_v]))\n",
    "        else:\n",
    "            np.savetxt(f'{savePath}/{prtx}mean.txt', np.asarray([psnr]))\n",
    "    return PSNRs\n",
    "\n",
    "\n",
    "class TensoRFTrainer:\n",
    "    def __init__(self, args: DictConfig):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.device = 'cpu' if not torch.cuda.is_available() else 'cuda'\n",
    "        self.renderer = TensoRFRenderer()\n",
    "\n",
    "        pass\n",
    "\n",
    "    def train(self):\n",
    "        args = self.args\n",
    "        device = self.device\n",
    "        renderer = self.renderer\n",
    "\n",
    "        # init dataset\n",
    "        train_dataset = BlenderDataset(args.datadir, split='train', downsample=args.downsample_train, is_stack=False)\n",
    "        test_dataset = BlenderDataset(args.datadir, split='test', downsample=args.downsample_train, is_stack=True)\n",
    "        white_bg = train_dataset.white_bg\n",
    "        near_far = train_dataset.near_far\n",
    "        ndc_ray = args.ndc_ray\n",
    "\n",
    "        # init resolution\n",
    "        upsamp_list = args.upsamp_list\n",
    "        update_AlphaMask_list = args.update_AlphaMask_list\n",
    "        n_lamb_sigma = args.n_lamb_sigma\n",
    "        n_lamb_sh = args.n_lamb_sh\n",
    "\n",
    "        if args.add_timestamp:\n",
    "            logfolder = f'{args.basedir}/{args.expname}{datetime.datetime.now().strftime(\"-%Y%m%d-%H%M%S\")}'\n",
    "        else:\n",
    "            logfolder = f'{args.basedir}/{args.expname}'\n",
    "\n",
    "        # init log file\n",
    "        os.makedirs(logfolder, exist_ok=True)\n",
    "        os.makedirs(f'{logfolder}/imgs_vis', exist_ok=True)\n",
    "        os.makedirs(f'{logfolder}/imgs_rgba', exist_ok=True)\n",
    "        os.makedirs(f'{logfolder}/rgba', exist_ok=True)\n",
    "        summary_writer = SummaryWriter(logfolder)\n",
    "\n",
    "        # init parameters\n",
    "        # tensorVM, renderer = init_parameters(args, train_dataset.scene_bbox.to(device), reso_list[0])\n",
    "        aabb = train_dataset.scene_bbox.to(device)\n",
    "        reso_cur = N_to_reso(args.N_voxel_init, aabb)\n",
    "        nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n",
    "\n",
    "        if args.ckpt is not None:\n",
    "            ckpt = torch.load(args.ckpt, map_location=device)\n",
    "            kwargs = ckpt['kwargs']\n",
    "            kwargs.update({'device': device})\n",
    "            tensorf = eval(args.model_name)(**kwargs)\n",
    "            tensorf.load(ckpt)\n",
    "        else:\n",
    "            tensorf = eval(args.model_name)(aabb, reso_cur, device,\n",
    "                                            density_n_comp=n_lamb_sigma, appearance_n_comp=n_lamb_sh,\n",
    "                                            app_dim=args.data_dim_color, near_far=near_far,\n",
    "                                            shadingMode=args.shadingMode, alphaMask_thres=args.alpha_mask_thre,\n",
    "                                            density_shift=args.density_shift, distance_scale=args.distance_scale,\n",
    "                                            pos_pe=args.pos_pe, view_pe=args.view_pe, fea_pe=args.fea_pe,\n",
    "                                            featureC=args.featureC, step_ratio=args.step_ratio,\n",
    "                                            fea2denseAct=args.fea2denseAct)\n",
    "\n",
    "        grad_vars = tensorf.get_optparam_groups(args.lr_init, args.lr_basis)\n",
    "        if args.lr_decay_iters > 0:\n",
    "            lr_factor = args.lr_decay_target_ratio ** (1 / args.lr_decay_iters)\n",
    "        else:\n",
    "            args.lr_decay_iters = args.n_iters\n",
    "            lr_factor = args.lr_decay_target_ratio ** (1 / args.n_iters)\n",
    "\n",
    "        print(\"lr decay\", args.lr_decay_target_ratio, args.lr_decay_iters)\n",
    "\n",
    "        optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n",
    "\n",
    "        # linear in logrithmic space\n",
    "        N_voxel_list = (torch.round(torch.exp(torch.linspace(np.log(args.N_voxel_init), np.log(args.N_voxel_final),\n",
    "                                                             len(upsamp_list) + 1))).long()).tolist()[1:]\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        PSNRs, PSNRs_test = [], [0]\n",
    "\n",
    "        allrays, allrgbs = train_dataset.all_rays, train_dataset.all_rgbs\n",
    "        if not args.ndc_ray:\n",
    "            allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs, bbox_only=True)\n",
    "        trainingSampler = SimpleSampler(allrays.shape[0], args.batch_size)\n",
    "\n",
    "        Ortho_reg_weight = args.Ortho_weight\n",
    "        print(\"initial Ortho_reg_weight\", Ortho_reg_weight)\n",
    "\n",
    "        L1_reg_weight = args.L1_weight_inital\n",
    "        print(\"initial L1_reg_weight\", L1_reg_weight)\n",
    "        TV_weight_density, TV_weight_app = args.TV_weight_density, args.TV_weight_app\n",
    "        tvreg = TVLoss()\n",
    "        print(f\"initial TV_weight density: {TV_weight_density} appearance: {TV_weight_app}\")\n",
    "\n",
    "        pbar = tqdm(range(args.n_iters), miniters=args.progress_refresh_rate, file=sys.stdout)\n",
    "        for iteration in pbar:\n",
    "\n",
    "            ray_idx = trainingSampler.nextids()\n",
    "            rays_train, rgb_train = allrays[ray_idx], allrgbs[ray_idx].to(device)\n",
    "\n",
    "            # rgb_map, alphas_map, depth_map, weights, uncertainty\n",
    "            rgb_map, alphas_map, depth_map, weights, uncertainty = renderer(rays_train, tensorf,\n",
    "                                                                            chunk=args.batch_size,\n",
    "                                                                            N_samples=nSamples, white_bg=white_bg,\n",
    "                                                                            ndc_ray=ndc_ray, device=device,\n",
    "                                                                            is_train=True)\n",
    "\n",
    "            loss = torch.mean((rgb_map - rgb_train) ** 2)\n",
    "\n",
    "            # loss\n",
    "            total_loss = loss\n",
    "            if Ortho_reg_weight > 0:\n",
    "                loss_reg = tensorf.vector_comp_diffs()\n",
    "                total_loss += Ortho_reg_weight * loss_reg\n",
    "                summary_writer.add_scalar('train/reg', loss_reg.detach().item(), global_step=iteration)\n",
    "            if L1_reg_weight > 0:\n",
    "                loss_reg_L1 = tensorf.density_L1()\n",
    "                total_loss += L1_reg_weight * loss_reg_L1\n",
    "                summary_writer.add_scalar('train/reg_l1', loss_reg_L1.detach().item(), global_step=iteration)\n",
    "\n",
    "            if TV_weight_density > 0:\n",
    "                TV_weight_density *= lr_factor\n",
    "                loss_tv = tensorf.TV_loss_density(tvreg) * TV_weight_density\n",
    "                total_loss = total_loss + loss_tv\n",
    "                summary_writer.add_scalar('train/reg_tv_density', loss_tv.detach().item(), global_step=iteration)\n",
    "            if TV_weight_app > 0:\n",
    "                TV_weight_app *= lr_factor\n",
    "                loss_tv = tensorf.TV_loss_app(tvreg) * TV_weight_app\n",
    "                total_loss = total_loss + loss_tv\n",
    "                summary_writer.add_scalar('train/reg_tv_app', loss_tv.detach().item(), global_step=iteration)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss = loss.detach().item()\n",
    "\n",
    "            PSNRs.append(-10.0 * np.log(loss) / np.log(10.0))\n",
    "            summary_writer.add_scalar('train/PSNR', PSNRs[-1], global_step=iteration)\n",
    "            summary_writer.add_scalar('train/mse', loss, global_step=iteration)\n",
    "\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group['lr'] = param_group['lr'] * lr_factor\n",
    "\n",
    "            # Print the current values of the losses.\n",
    "            if iteration % args.progress_refresh_rate == 0:\n",
    "                pbar.set_description(\n",
    "                    f'Iteration {iteration:05d}:'\n",
    "                    + f' train_psnr = {float(np.mean(PSNRs)):.2f}'\n",
    "                    + f' test_psnr = {float(np.mean(PSNRs_test)):.2f}'\n",
    "                    + f' mse = {loss:.6f}'\n",
    "                )\n",
    "                PSNRs = []\n",
    "\n",
    "            if iteration % args.vis_every == args.vis_every - 1 and args.N_vis != 0:\n",
    "                PSNRs_test = evaluation(test_dataset, tensorf, args, renderer, f'{logfolder}/imgs_vis/',\n",
    "                                        N_vis=args.N_vis,\n",
    "                                        prtx=f'{iteration:06d}_', N_samples=nSamples, white_bg=white_bg,\n",
    "                                        ndc_ray=ndc_ray, compute_extra_metrics=False)\n",
    "                summary_writer.add_scalar('test/psnr', np.mean(PSNRs_test), global_step=iteration)\n",
    "\n",
    "            if iteration in update_AlphaMask_list:\n",
    "\n",
    "                if reso_cur[0] * reso_cur[1] * reso_cur[2] < 256 ** 3:  # update volume resolution\n",
    "                    reso_mask = reso_cur\n",
    "                new_aabb = tensorf.updateAlphaMask(tuple(reso_mask))\n",
    "                if iteration == update_AlphaMask_list[0]:\n",
    "                    tensorf.shrink(new_aabb)\n",
    "                    # tensorVM.alphaMask = None\n",
    "                    L1_reg_weight = args.L1_weight_rest\n",
    "                    print(\"continuing L1_reg_weight\", L1_reg_weight)\n",
    "\n",
    "                if not args.ndc_ray and iteration == update_AlphaMask_list[1]:\n",
    "                    # filter rays outside the bbox\n",
    "                    allrays, allrgbs = tensorf.filtering_rays(allrays, allrgbs)\n",
    "                    trainingSampler = SimpleSampler(allrgbs.shape[0], args.batch_size)\n",
    "\n",
    "            if iteration in upsamp_list:\n",
    "                n_voxels = N_voxel_list.pop(0)\n",
    "                reso_cur = N_to_reso(n_voxels, tensorf.aabb)\n",
    "                nSamples = min(args.nSamples, cal_n_samples(reso_cur, args.step_ratio))\n",
    "                tensorf.upsample_volume_grid(reso_cur)\n",
    "\n",
    "                if args.lr_upsample_reset:\n",
    "                    print(\"reset lr to initial\")\n",
    "                    lr_scale = 1  # 0.1 ** (iteration / args.n_iters)\n",
    "                else:\n",
    "                    lr_scale = args.lr_decay_target_ratio ** (iteration / args.n_iters)\n",
    "                grad_vars = tensorf.get_optparam_groups(args.lr_init * lr_scale, args.lr_basis * lr_scale)\n",
    "                optimizer = torch.optim.Adam(grad_vars, betas=(0.9, 0.99))\n",
    "\n",
    "        tensorf.save(f'{logfolder}/{args.expname}.th')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/mmfs1/project/jacobcha/nk643/TensoRFReproduce/runner/trainer'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neural_point_render_cha",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
