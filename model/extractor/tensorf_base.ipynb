{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import torch"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import sys\n","sys.path.append('/project/jacobcha/nk643/TensoRFReproduce')\n","from data.blender import BlenderDataset"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["device = \"cuda\"\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["train_dataset = BlenderDataset(\"/project/jacobcha/nk643/data_src/nerf_synthetic/lego\", split='train', downsample=1.0, is_stack=False)\n","aabb = train_dataset.scene_bbox.to(device)\n"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-04-16 16:15:25.317059: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n","2024-04-16 16:15:26.135496: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2024-04-16 16:15:26.135558: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2024-04-16 16:15:26.263822: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2024-04-16 16:15:26.478924: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2024-04-16 16:15:31.751022: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"]}],"source":["from runner.trainer.tensorf_utils import N_to_reso\n","reso_cur = N_to_reso(2097156, aabb)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["def positional_encoding(positions, freqs):\n","    freq_bands = (2 ** torch.arange(freqs).float()).to(positions.device)  # (F,)\n","    pts = (positions[..., None] * freq_bands).reshape(\n","        positions.shape[:-1] + (freqs * positions.shape[-1],))  # (..., DF)\n","    pts = torch.cat([torch.sin(pts), torch.cos(pts)], dim=-1)\n","    return pts"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["class MLPRender_Fea(torch.nn.Module):\n","    def __init__(self, inChanel, viewpe = 6, feape = 6, featureC = 128):\n","        super(MLPRender_Fea, self).__init__()\n","\n","        #NOTE: Did not understand why exactly the following is done\n","        #TODO: Revise the paper when the renderer is called\n","        self.in_mlpC = 2 * viewpe * 3 + 2 * feape * inChanel + 3 + inChanel\n","        self.viewpe = viewpe\n","        self.feape = feape\n","\n","        self.mlp = torch.nn.Sequential(\n","            torch.nn.Linear(self.in_mlpC, featureC),\n","            torch.nn.ReLU(inplace=True),\n","            torch.nn.Linear(featureC, featureC),\n","            torch.nn.ReLU(inplace=True),\n","            torch.nn.Linear(featureC, 3)) # 3 for RGB\n","        \n","        torch.nn.init.constant_(self.mlp[-1].weight, 0)\n","\n","    def forward(self, pts, viewdirs, features):\n","        indata = [features, viewdirs]\n","\n","        if self.feape > 0:\n","            indata.append(positional_encoding(pts, self.feape))\n","        if self.viewpe > 0:\n","            indata.append(positional_encoding(pts, self.viewpe))\n","\n","        mlp_in = torch.cat(indata, dim=-1)\n","        return torch.sigmoid(self.mlp(mlp_in)) #RGB\n","\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["class TensorBase(torch.nn.Module):\n","    def __init__(self, aabb, gridSize, device, density_n_comp=8, appearance_n_comp=24, app_dim=27,\n","                 shadingMode='MLP_PE', alphaMask=None, near_far=[2.0, 6.0],\n","                 density_shift=-10, alphaMask_thres=0.001, distance_scale=25, rayMarch_weight_thres=0.0001,\n","                 pos_pe=6, view_pe=6, fea_pe=6, featureC=128, step_ratio=2.0,\n","                 fea2denseAct='softplus'):\n","        super(TensorBase, self).__init__()\n","\n","        self.density_n_comp = density_n_comp\n","        self.app_n_comp = appearance_n_comp\n","        self.app_dim = app_dim\n","        self.aabb = aabb\n","        self.alphaMask = alphaMask\n","        self.device = device\n","\n","        #NOTE: What are these?\n","        self.density_shift = density_shift\n","        self.alphaMask_thres = alphaMask_thres\n","        self.distance_scale = distance_scale\n","        self.rayMarch_weight_thres = rayMarch_weight_thres\n","        self.fea2denseAct = fea2denseAct\n","\n","        self.near_far = near_far\n","        self.step_ratio = step_ratio\n","\n","        self.updateStepSize(gridSize)\n","\n","        \n","        self.init_svd_volume(gridSize[0], device)\n","\n","        self.shadingMode, self.pos_pe, self.view_pe, self.fea_pe, self.featureC = shadingMode, pos_pe, view_pe, fea_pe, featureC\n","\n","        self.init_render_func(shadingMode, pos_pe, view_pe, fea_pe, featureC, device)\n","\n","    def updateStepSize(self, gridSize):\n","        #NOTE: I think this is for ray sampling\n","        self.aabbSize = self.aabb[1] - self.aabb[0]\n","        #NOTE: Why is the inverse 2/x? is it because ndc is -1 to 1?\n","        self.invaabbSize = 2.0/self.aabbSize[0]\n","        self.gridSize = torch.LongTensor(gridSize).to(self.device)\n","        print(self.gridSize - 1)\n","        self.units = self.aabbSize/(self.gridSize - 1)\n","        self.stepSize = torch.mean(self.units) * self.step_ratio\n","        #NOTE: Presumably the length of the ray is the length of the diagnoal\n","        self.aabbDiag = torch.norm(self.aabbSize)\n","        #NOTE: I think this is the number of samples per ray\n","        self.nSamples = int((self.aabbDiag/ self.stepSize).max())\n","\n","\n","    def init_svd_volume(self, res, device):\n","        pass\n","\n","    def init_render_func(self, shadingMode, pos_pe, view_pe, fea_pe, featureC, device):\n","        pass\n","        if shadingMode == \"MLP_Fea\":\n","            self.renderingModule = MLPRender_Fea(self.app_dim, view_pe, fea_pe, featureC).to(device)\n","        #TODO: Implement other shading modes\n","        else:\n","            raise NotImplementedError(\"Shading mode not implemented\")\n","    \n","    #TODO: Implement the forward prop for the model\n","    def forward():\n","        pass\n","\n"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([127, 127, 127], device='cuda:0')\n"]},{"data":{"text/plain":["TensorBase(\n","  (renderingModule): MLPRender_Fea(\n","    (mlp): Sequential(\n","      (0): Linear(in_features=390, out_features=128, bias=True)\n","      (1): ReLU(inplace=True)\n","      (2): Linear(in_features=128, out_features=128, bias=True)\n","      (3): ReLU(inplace=True)\n","      (4): Linear(in_features=128, out_features=3, bias=True)\n","    )\n","  )\n",")"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["TensorBase(aabb, reso_cur, device, density_n_comp=8, appearance_n_comp=24, app_dim=27,\n","                 shadingMode='MLP_Fea', alphaMask=None, near_far=[2.0, 6.0],\n","                 density_shift=-10, alphaMask_thres=0.001, distance_scale=25, rayMarch_weight_thres=0.0001,\n","                 pos_pe=6, view_pe=6, fea_pe=6, featureC=128, step_ratio=2.0,\n","                 fea2denseAct='softplus')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"neural_point_render_cha","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":2}
